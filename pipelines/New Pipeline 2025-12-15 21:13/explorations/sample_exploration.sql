-- Databricks notebook source
-- MAGIC %md
-- MAGIC ### Example Exploratory Notebook
-- MAGIC
-- MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
-- MAGIC
-- MAGIC **Note**: This notebook is not executed as part of the pipeline.

-- COMMAND ----------

-- MAGIC %python
-- MAGIC import sys
-- MAGIC
-- MAGIC sys.path.append("/Workspace/Users/franciscojavier.martindeblas@databricks.com/project_77/pipelines/New Pipeline 2025-12-15 21:13")

-- COMMAND ----------

-- !!! Before performing any data analysis, make sure to run the pipeline to materialize the sample datasets. The tables referenced in this notebook depend on that step.

USE CATALOG `francisco_martin_workspace`;
USE SCHEMA `default`;

SELECT * from sample_aggregation_dec_15_2113;

-- COMMAND ----------

  SELECT *
  FROM STREAM READ_FILES(
    '/Volumes/francisco_martin_workspace/project_77_indicators/indicator_metrics',
    format => 'json'
  );

-- COMMAND ----------

SELECT from_json('{"a":{"name": "abc"}}', 'abc STRING').a.abc ;

-- COMMAND ----------

SELECT indicator.name
FROM STREAM READ_FILES(
  '/Volumes/francisco_martin_workspace/project_77_indicators/indicator_metrics',
  format => 'json',
  schema => '
  indicator STRUCT<
    name: STRING,
    short_name: STRING,
    id: LONG,
    composited: BOOLEAN,
    step_type: STRING,
    disaggregated: BOOLEAN,
    magnitud: ARRAY<STRUCT<name: STRING, id: LONG>>,
    tiempo: ARRAY<STRUCT<name: STRING, id: LONG>>,
    geos: ARRAY<STRUCT<geo_id: LONG, geo_name: STRING>>,
    values_updated_at: STRING,
    values: ARRAY<STRUCT<
      value: DOUBLE,
      datetime: STRING,
      datetime_utc: STRING,
      tz_time: STRING,
      geo_ids: ARRAY<LONG>
    >>
  >'
)
LATERAL VIEW explode(indicator.values) AS measurements

-- COMMAND ----------

DROP STREAMING TABLE francisco_martin_workspace.project_77_indicators.indicator_raw;

-- COMMAND ----------


